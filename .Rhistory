library(twitteR)
rdmTweets <- userTimeline("rdatamining", n=100)
rdmTweets <- userTimeline("PiyushJain261", n=100)
api_key<-"Esu0Wh64vUYLd0Lb8G0Szokbx"
api_secret<-"CXoQBuQIrQpkhDA1ectxefrpBietdokC4PYECXGS0HHlrgv5Uy
api_secret<-"CXoQBuQIrQpkhDA1ectxefrpBietdokC4PYECXGS0HHlrgv5Uy"
api_secret<-"CXoQBuQIrQpkhDA1ectxefrpBietdokC4PYECXGS0HHlrgv5Uy"
setup_twitter_oauth(api_key,api_secret)
setup_twitter_oauth(api_key,api_secret)
setup_twitter_oauth(api_key, api_secret, access_token=NULL, access_secret=NULL)
setup_twitter_oauth(api_key, api_secret, ,)
access_token="40823584-EAcCabyg1nazN7JBZEbmBwJAvyP7wuh2trV1pfuFY"
access_secre<-"QBiQxnQ185K2fM0GKRbckSDwQJnSWIFjUyc1jfexpOHLA"
access_secret<-"QBiQxnQ185K2fM0GKRbckSDwQJnSWIFjUyc1jfexpOHLA"
access_token
access_secret
setup_twitter_oauth(api_key, api_secret,access_token,access_secret)
save()
getwd()
setwd("D:/twitteR/.RData")
setwd("D:/twitteR/")
save(file="D:/twitteR/.RData")
savehistory()
save()
api_key<-"Esu0Wh64vUYLd0Lb8G0Szokbx"
api_secret<-"CXoQBuQIrQpkhDA1ectxefrpBietdokC4PYECXGS0HHlrgv5Uy"
access_token="40823584-EAcCabyg1nazN7JBZEbmBwJAvyP7wuh2trV1pfuFY"
access_secret<-"QBiQxnQ185K2fM0GKRbckSDwQJnSWIFjUyc1jfexpOHLA"
setup_twitter_oauth(api_key, api_secret,access_token,access_secret)
rdmTweets <- userTimeline("PiyushJain261", n=100)
rdmTweets
rdmTweets[[1:3]]
rdmTweets[1:3]
rdmTweets1 <- userTimeline("VasundharaBJP", n=100)
rdmTweets1
save()
save(file=".RData")
save(,file=".RData")
rdmTweets[1:3]
rdmTweets1
tweets<-searchTwitter("kota",n=10)
tweets
tweets<-searchTwitter("kota rajasthan",n=10)
tweets
tweets<-searchTwitter("kota rajasthan",n=5)
tweets
tweets<-searchTwitter("Start Up",n=5)
tweets
n <- length(rdmTweets)
n <- length(rdmTweets1)
df <- do.call("rbind", lapply(rdmTweets1, as.data.frame))
 dim(df)
df <- do.call("rbind", lapply(rdmTweets, as.data.frame))
dim(df)
library(tm
)
install.packages(tm)
install.package(tm)
install.packages("tm")
library(tm)
After that, the corpus needs a couple of transformations, including changing letters to lower case, removing punctuations/numbers and removing stop words. The general English stop-word list is tailored by adding "available" and "via" and removing "r".
myCorpus <- Corpus(VectorSource(df$text))
myCorpus <- tm_map(myCorpus, tolower)
> # remove punctuation
myCorpus <- tm_map(myCorpus, removePunctuation)
> # remove numbers
> myCorpus <- tm_map(myCorpus, removeNumbers)
> # remove stopwords
> # keep "r" by removing it from stopwords
> myStopwords <- c(stopwords('english'), "available", "via")
> idx <- which(myStopwords == "r")
> myStopwords <- myStopwords[-idx]
> myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
myCorpus <- Corpus(VectorSource(df$text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myStopwords <- c(stopwords('english'), "available", "via")
idx <- which(myStopwords == "r")
> myStopwords <- myStopwords[-idx]
> myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
idx <- which(myStopwords == "r")
myStopwords <- myStopwords[-idx]
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
myCorpus <- tm_map(myCorpus, stemDocument)
inspect(myCorpus[1:3])
myDtm <- TermDocumentMatrix(myCorpus, control = list(minWordLength = 1))
inspect(myDtm[266:270,31:40])
inspect(myDtm[,])
findFreqTerms(myDtm, lowfreq=10)
[1] "analysis" "data" "examples" "miners" "package" "r" "slides"
[8] "tutorial" "users"
findFreqTerms(myDtm, lowfreq=10)
library(wordcloud)
install.packages("wordcloud")
library(wordcloud)
m <- as.matrix(myDtm)
v <- sort(rowSums(m), decreasing=TRUE)
myNames <- names(v)
k <- which(names(v)=="miners")
d <- data.frame(word=myNames, freq=v)
wordcloud(d$word, d$freq, min.freq=3)
save(,file=".RData")
save(file=".RData")
save(file="a.RData")
rdmTweets1
tweets<-searchTwitter("Start Up",n=5)
history()
savehistory()
n <- length(rdmTweets1)
df <- do.call("rbind", lapply(rdmTweets1, as.data.frame))
wordcloud(d$word, d$freq, min.freq=3)
df
 dim(df)
myCorpus <- Corpus(VectorSource(df$text))
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myStopwords <- c(stopwords('english'), "available", "via")
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
myDtm <- TermDocumentMatrix(myCorpus, control = list(minWordLength = 1))
inspect(myDtm[266:270,31:40])
m <- as.matrix(myDtm)
v <- sort(rowSums(m), decreasing=TRUE)
myNames <- names(v)
d <- data.frame(word=myNames, freq=v)
wordcloud(d$word, d$freq, min.freq=100)
wordcloud(d$word, d$freq, min.freq=5)
wordcloud(d$word, d$freq, min.freq=500)
wordcloud(d$word, d$freq, min.freq=50)
wordcloud(d$word, d$freq, min.freq=1000)
wordcloud(d$word, d$freq, min.freq=10000)
wordcloud(d$word, d$freq, min.freq=1000000)
wordcloud(d$word, d$freq, min.freq=10000000000)
?wordcloud()
wordcloud(d$word, d$freq, min.freq=4)
wordcloud(d$word, d$freq, min.freq=2)
wordcloud(d$word, d$freq, min.freq=2,ordered,colors=TRUE)
wordcloud(d$word, d$freq, min.freq=2,ordered.colors=TRUE)
wordcloud(d$word, d$freq, min.freq=2,ordered.colors=TRUE,max.words=TRUE)
wordcloud(d$word, d$freq, min.freq=1000,ordered.colors=TRUE,max.words=TRUE)
history()
